{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch15-2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jnuxB2zWaIiv"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJ8RmU0kWi7O20IHVPxCpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PingPingE/Learn_ML_DL/blob/main/Practice/Hands_On_ML/ch15-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTfKFBs3C4TL"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9pT0qxJy2tz"
      },
      "source": [
        "# 긴 시퀀스 다루기\n",
        "- 문제점 및 해결 방법(ch15-1에서 왜 tanh가 디폴트인지 알아보면서 살짝 다룸)\n",
        "  - gradient 소실 또는 폭주 문제 -> 불안정한 학습\n",
        "  - RNN이 긴 시퀀스를 처리할 때 입력의 첫 부분을 조금씩 잊어버리는 문제 \n",
        "  - 해결 방법\n",
        "    - [gradient clipping](https://sanghyu.tistory.com/87)\n",
        "    - 낮은 learning rate\n",
        "    - 정규화 \n",
        "    - 장기 메모리 셀\n",
        "<br><br>\n",
        "- RNN에 잘맞는 종류의 정규화: <strong>층 정규화</strong>(ch13-2에서 살짝 다룸)\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcdaNCJ%2FbtqAa7RVwhD%2FP60H1iai2Mxgvu09TGQpv0%2Fimg.png\" width=80% height=80%/>\n",
        "\n",
        "  - 즉, 배치 정규화는 배치 차원에 대해 정규화, 층 정규화는 <strong>특성 차원에 대해 정규화</strong>\n",
        "  - 그래서 훈련과 테스트에서 동일한 방식으로 작동한다.\n",
        "    - 배치 정규화는 훈련 세트의 모든 세트에 대한 특성 통계를 추정하기 위해 지수 이동 평균이 필요했음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPJ3qhKy0e-C"
      },
      "source": [
        "## 메모리 셀 안에 층 정규화 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uw0lAKU0ejQ"
      },
      "source": [
        "class LNSimpleRNNCell(keras.layers.Layer):\n",
        "  def __init__(self, units, activation=\"tanh\", **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.state_size=units\n",
        "    self.output_size=units\n",
        "    self.simple_rnn_cell=keras.layers.SimpleRNNCell(units,activation=None)#===포인트: activation=None이다(활성화 함수에 넣기 전에 정규화하려고)\n",
        "    self.layer_norm=keras.layers.LayerNormalization()\n",
        "    self.activation=keras.activations.get(activation)\n",
        "  \n",
        "  def call(self, inputs, states):#====현재 타임 스텝의 inputs와 이전 타임 스텝의 hidden states(h_t-1)\n",
        "    outputs, new_states= self.simple_rnn_cell(inputs, states)\n",
        "    norm_outputs=self.activation(self.layer_norm(outputs)) #정규화하고 난 후의 값을 활성화 함수에 대입\n",
        "    return norm_outputs, [norm_outputs] #===두 개인 이유: 하나는 출력, 하나는 새로운 은닉 상태(h_t)가 된다\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDpPN0K_4FqX"
      },
      "source": [
        "- 사용자 정의 셀 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cowBiOFmzBpw"
      },
      "source": [
        "model=keras.models.Sequential([\n",
        "                               keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),\n",
        "                               keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
        "                               keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piylMGsX4d8F"
      },
      "source": [
        "-----------\n",
        "위 처럼 keras.layers.RNN층을 만들어서 LNSimpleRNNCell의 객체를 전달하면 된다.\n",
        "- 만약 타임 스텝 사이에 dropout을 적용하고 싶다면?\n",
        "  - 위처럼 드롭아웃을 적용하는 사용자 정의 셀을 만들어도 되긴하는데, \n",
        "  - keras.layers.SimpleRNN(recurrent_dropout=0.5) 매개변수를 지원함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX6N8thd5VQF"
      },
      "source": [
        "## LSTM(Long Short-Term Memory) 셀\n",
        "- RNN을 거치면서 데이터가 변환되므로 일부 정보는 매 훈련 스텝 후 사라짐\n",
        "- 그래서 어느 정도 시간이 지나면 사실상 <strong>첫 번째 입력의 흔적이 사라짐</strong>\n",
        "- 몇몇문제는 위 특징이 심각한 문제가 될 수 있음 그래서 <strong>장기 메모리</strong>를 가진 여러 종류의 셀이 연구됨\n",
        "- 장기 메모리를 가진 셀에서 가장 인기있는게 <strong>LSTM셀</strong>\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Xiaofeng-Yuan-4/publication/331421650/figure/fig2/AS:771405641695233@1560928845927/The-structure-of-the-LSTM-unit.png\" width=50% height=50%/>\n",
        "\n",
        "- 핵심 아이디어: 네트워크가 <strong>장기 상태에 저장</strong>할 것, <strong>버릴 것</strong>, 그리고 <strong>읽어들일 것</strong>을 학습하는 것\n",
        "- h_t: 단기 상태(short-term state)\n",
        "- c_t: 장기 상태(long-term state) \n",
        "- 로직\n",
        "  - 장기기억 c_t-1은 왼->오른쪽으로 관통하면서 <strong>삭제 게이트(f_t)를 지나 일부 기억을 잃는다.</strong>\n",
        "  - 그런 다음 <strong>입력 게이트(i_t)에서 새로운 기억 일부가 추가</strong>된다.\n",
        "  - 만들어진 c_t는 다른 <strong>추가 변환 없이 바로 출력</strong>으로 보내진다.\n",
        "  - h_t는 c_t가 복사되어 <strong>tanh함수</strong>를 거친 후 <strong>결과 게이트(o_t)</strong>에서 걸러서 만들어진다.\n",
        "    - o_t는 장기 상태의 어느 부분을 읽어서 이 타임 스텝의 h_t와 y_t로 출력해야 하는지 제어한다.\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnuxB2zWaIiv"
      },
      "source": [
        "### 적용 방법\n",
        "- SImpleRNN 대신 LSTM 층 사용\n",
        "  - 이 방법을 일반적으로 많이 사용(GPU에서 실행할 때 최적화된 구현을 사용해서)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMzdjslZCL0"
      },
      "source": [
        "model2= keras.models.Sequential([\n",
        "                                 keras.layers.LSTM(20,return_sequences=True, input_shape=[None, 1]),\n",
        "                                 keras.layers.LSTM(20, return_sequences=True),\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d5qcsTHaAhM",
        "outputId": "910a2143-d4eb-4e56-a595-d3f07a1d3508"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, None, 20)          1760      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 20)          3280      \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 10)          210       \n",
            "=================================================================\n",
            "Total params: 5,250\n",
            "Trainable params: 5,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HWaM5Szaox2"
      },
      "source": [
        "- RNN층에 LSTMCell을 매개변수로 지정할 수도 있음\n",
        "  - 이 방법은 사용자 정의 셀을 정의할 때 많이 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZIPXPmUaCAg"
      },
      "source": [
        "model3 = keras.models.Sequential([\n",
        "                                  keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True, input_shape=[None, 1]),\n",
        "                                  keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True),\n",
        "                                  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lPrp3xDbC-v",
        "outputId": "dc55bd58-ebb8-48e0-9f29-bfc7427a5883"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn_1 (RNN)                  (None, None, 20)          1760      \n",
            "_________________________________________________________________\n",
            "rnn_2 (RNN)                  (None, None, 20)          3280      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 10)          210       \n",
            "=================================================================\n",
            "Total params: 5,250\n",
            "Trainable params: 5,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "586bOh1cbDzA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}