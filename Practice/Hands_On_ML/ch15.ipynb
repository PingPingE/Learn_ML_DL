{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3GifOmk54c+P1MZZ7mmdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PingPingE/Learn_ML_DL/blob/main/Practice/Hands_On_ML/ch15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uI7mGlgceTn"
      },
      "source": [
        "# RNN과 CNN을 사용해 시퀀스 처리하기\n",
        "- 순차 데이터를 다룬다.\n",
        "- 하지만 순차 데이터를 디루는 유일한 신경망은 아니다.\n",
        "  - 짧은 시퀀스: Dense 네트워크가 처리 가능\n",
        "  - 긴 시퀀스: Conv 네트워크가 처리 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuaveHU7db0M"
      },
      "source": [
        "## 순한 뉴런과 순환 층\n",
        "<img src=\"https://media.vlpt.us/images/changdaeoh/post/3afed92b-978e-4173-bc56-d8453c7f2b8f/image.png\"/>\n",
        "\n",
        "- RNN은 피드포워드 신경망과 매우 비슷하지만, \n",
        "- <strong>뒷쪽</strong>으로 순환하는 연결도 있다는 점이 다르다.\n",
        "- 위 처럼 <strong>각 타임  스텝 t(또는 frame)마다 x_(t)와 이전 타임 스텝의 출력인 y_(t-1)를 입력</strong>으로 받는다.\n",
        "  - 첫 번째 타임 스텝은 이전 출력이 없으므로 일반적으로 0으로 설정\n",
        "  - 각 뉴런은 <strong>가중치도 두 개</strong>를 가진다.(하나는 x_(t), 다른 하나는 y_(t-1)를 위한 것)\n",
        "  <img src=\"https://media.vlpt.us/images/changdaeoh/post/355c3d96-9e65-48fd-9ad6-6b2ba9f116b3/image.png\" width= 50%  height=50%/>\n",
        "  - 즉, Y_(t)는 시간 t=0에서부터 모든 입력에 대한 함수가 된다.\n",
        "- 동일한 뉴런을 타임 스텝마다 하나씩 표현한 위 이미지를, '시간에 따라 네트워크를 펄쳤다'고 말한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HNXeS82gY6C"
      },
      "source": [
        "## 메모리 셀\n",
        "- 타임 스텝 t에서 순환 뉴런의 출력은 이전 타임 스텝의 모든 입력에 대한 함수이므로, 이를 일종의 <strong>메모리</strong> 형태라고 말할 수 있다.\n",
        "- <strong>메모리 셀:</strong> 타임 스텝에 걸쳐서 <strong>어떤 상태를 보존</strong>하는 신경망의 구성 요소\n",
        "- 각 스텝 t에서 셀의 상태 h_(t)는 (h: hidden) 그 타임 스텝의 입력과 이전 타임 스텝의 상태에 대한 함수이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "  <img src=\"https://media.vlpt.us/images/changdaeoh/post/797fafe5-5df8-424e-8adc-fe654afbb43c/image.png\"/>\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REWZx6kRirX2"
      },
      "source": [
        "## 입력과 출력 시퀀스\n",
        "- <strong>벡터-투-시퀀스</strong>\n",
        "  - 각 타임 스텝에서 하나의 입력 벡터를 반복해서 주입하고, 하나의 시퀀스 출력\n",
        "  - ex) 이미지 주입 -> 이미지 캡션 출력\n",
        "\n",
        "- <strong>시퀀스-투-벡터</strong>\n",
        "  - 입력 시퀀스를 주입하고 마지막을 제외한 모든 출력을 무시\n",
        "  - ex) 영화 리뷰에 있는 연속된 단어를 주입 -> 감성 점수 출력(싫다(-1)~좋다(+1))\n",
        "\n",
        "- <strong>시퀀스-투-시퀀스</strong>\n",
        "  - 입력 시퀀스를 받아 출력 시퀀스를 만든다.\n",
        "  - ex) 최근 N일치의 주식가격 주입 -> 각 입력값보다 하루 앞선 가격 출력\n",
        "  - (즉, N-1일 전부터 내일까지)\n",
        "\n",
        "- <strong>인코더-디코더</strong>\n",
        "   - 시퀀스-투-벡터 네트워크(인코더) 뒤에 벡터-투-시퀀스 네트워크(디코더) 연결\n",
        "   - ex) 한 언어의 문장을 다른 언어로 번역\n",
        "   - 인코더: 해당 문장을 하나의 벡터로 변환\n",
        "   - 디코더: 해당 벡터를 다른 언어의 문장으로 디코딩\n",
        "   - 왜 굳이 이중  모델? \n",
        "    - 하나의 시퀀스-투-시퀀스 네트워크보다 성능이 좋다.\n",
        "    - <strong>번역하기 전에 전체 문장이 주입될 때까지 기다려야 하기 때문</strong>\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F99A94F465BD1990B20352F\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCKawGxMmKx3"
      },
      "source": [
        "## RNN 훈련하기\n",
        "- BPTT(Backpropagation Through Time)\n",
        "<img src=\"https://media.vlpt.us/images/changdaeoh/post/333a8501-57cb-4bc6-8e11-4ca2172b4286/image.png\" width=50% height=50%/>\n",
        "\n",
        "  - 타임 스텝으로 네트워크를 펼치고(실제로 펼치진 않음)\n",
        "  - 보통의 역전파를 사용하는 것\n",
        "    - 정방향 패스 동안에는 <strong>모두 동일한 가중치</strong>가 적용된다(즉, 같은 매개변수 W,b사용)\n",
        "    - 그래서 역전파가 진행되면 <strong>모든 타임 스텝에 걸쳐 합산</strong>될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3WzGZHApAMx"
      },
      "source": [
        "## 시계열 예측하기\n",
        "- 시계열: 타임 스텝마다 하나 이상의 값을 가진 시퀀스\n",
        "  - 단변량 시계열: 하나의 값을 가지는 시퀀스(ex) 시간당 접속 사용자 수 예측)\n",
        "  - 다변량 시계열: 여러 값을 가지는 시퀀스(ex) 기업의 분기별 재정 안정성 예측 -> 수입/부채 등 고려)\n",
        "  - 보통 [배치 크기, 타임 스텝 수, 차원 수] 3D배열로 나타냄(단변량은 차원 수가 1)\n",
        "- 시계열 예측으로 값 대체도 가능\n",
        "  - 누락된 값 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ntg6tagOBF"
      },
      "source": [
        "import numpy as np\n",
        "def generate_time_series(batch_size, n_steps): #====batch_size만큼 n_steps 길이의 여러 시계열 생성\n",
        "  freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)\n",
        "  time= np.linspace(0,1,n_steps) #n_steps개의 0~1사이의 값을 가지는 1d배열 생성\n",
        "  series=0.5*np.sin((time-offset1)*(freq1*10+10))\n",
        "  series +=0.2*np.sin((time-offset2)*(freq1*20+20))\n",
        "  series +=0.1*(np.random.rand(batch_size, n_steps)-0.5) #잡음\n",
        "  return series[..., np.newaxis].astype(np.float32)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbgC9YOiq1LS"
      },
      "source": [
        "n_steps= 50\n",
        "series=generate_time_series(10000, n_steps+1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000,-1]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
        "X_test, y_test=series[9000:, :n_steps], series[9000:,-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd1U-Z-DrupS",
        "outputId": "d1917263-a6ad-4dff-f3b4-7b234f6064e7"
      },
      "source": [
        "series.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 51, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6QoMMwktJrF",
        "outputId": "6c206d2e-3fce-473c-e1ce-116b81b0e96d"
      },
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 50, 1) (7000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTOk77Szr-sh"
      },
      "source": [
        "---------------\n",
        "시계열마다 1개의 값 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1LMzpGctZ2F"
      },
      "source": [
        "### 기준 성능\n",
        "- 가장 간단한 방법: 각 시계열의 마지막 값을 그대로 예측 -> 순진한 예측이라고 함\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmEyA5jote4b",
        "outputId": "4bf3f092-e585-46d2-e5d9-6581ec7c1c3e"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "y_pred=X_valid[:,-1]\n",
        "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021428755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n76QzBP0t_Jq"
      },
      "source": [
        "- 완전 연결 네트워크를 사용하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Lz1M3xuCGJ"
      },
      "source": [
        "model1 = keras.models.Sequential([\n",
        "                                 keras.layers.Flatten(input_shape=[50,1]),\n",
        "                                 keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJTFxA5Ivtz7",
        "outputId": "39a44fc5-8e5d-41fe-d1f3-bced458d1e9d"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhMWstWnuNRu",
        "outputId": "bbbb4ab1-8035-45f1-ebc4-f333d7ab118e"
      },
      "source": [
        "model1.compile(optimizer='adam', loss='mse')\n",
        "model1.fit(X_train, y_train,validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 2ms/step - loss: 0.2090 - val_loss: 0.0619\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0343\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0208\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0139\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0107\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0090\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0079\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0056\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0ca929a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv4XnncPuhRD"
      },
      "source": [
        "-----------\n",
        "val_loss: 0.0040까지 떨어짐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFbs3bstfkK"
      },
      "source": [
        "### 간단한 RNN 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noMI5184unAq"
      },
      "source": [
        "model2= keras.models.Sequential(\n",
        "                                   keras.layers.SimpleRNN(1, input_shape=[None, 1])) #기본적으로 tanh 활성화 함수를 사용함"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIRKVqbTutlE",
        "outputId": "145271c1-4c7e-403d-b703-eb2c9238b4ee"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_3 (SimpleRNN)     (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__pUSbIDuzE6",
        "outputId": "ac06b411-b4f9-4698-ea99-a69f424ab3e0"
      },
      "source": [
        "model2.compile(optimizer='adam', loss='mse')\n",
        "model2.fit(X_train, y_train,validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 3s 8ms/step - loss: 0.2255 - val_loss: 0.1936\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1848 - val_loss: 0.1624\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1564 - val_loss: 0.1382\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1330 - val_loss: 0.1150\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1085 - val_loss: 0.0927\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0879 - val_loss: 0.0733\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0675 - val_loss: 0.0569\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0513 - val_loss: 0.0430\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0390 - val_loss: 0.0320\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0291 - val_loss: 0.0238\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0218 - val_loss: 0.0184\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0171 - val_loss: 0.0152\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0137\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0129\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0125\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0124\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0122\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0121\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0120\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0c785dad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBZwk8V_vk6L"
      },
      "source": [
        "--------\n",
        "val_loss가 0.0119로, 위 간단한 선형 모델(0.004)보다 좋지 못한 성능이지만, <br>\n",
        "파라미터가 3개로, 51개인 위 모델보다 훨씬 적다."
      ]
    }
  ]
}