{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO5rP9+EE4/gON3swHYQhzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PingPingE/Learn_ML_DL/blob/main/Practice/Hands_On_ML/ch15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uI7mGlgceTn"
      },
      "source": [
        "# RNN과 CNN을 사용해 시퀀스 처리하기\n",
        "- RNN은 순차 데이터를 다룬다.\n",
        "- 하지만 순차 데이터를 디루는 유일한 신경망은 아니다.\n",
        "  - 짧은 시퀀스: Dense 네트워크가 처리 가능\n",
        "  - 긴 시퀀스: Conv 네트워크가 처리 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuaveHU7db0M"
      },
      "source": [
        "## 순한 뉴런과 순환 층\n",
        "<img src=\"https://media.vlpt.us/images/changdaeoh/post/3afed92b-978e-4173-bc56-d8453c7f2b8f/image.png\"/>\n",
        "\n",
        "- RNN은 피드포워드 신경망과 매우 비슷하지만, \n",
        "- <strong>뒷쪽</strong>으로 순환하는 연결도 있다는 점이 다르다.\n",
        "- 위 처럼 <strong>각 타임  스텝 t(또는 frame)마다 x_(t)와 이전 타임 스텝의 출력인 y_(t-1)를 입력</strong>으로 받는다.\n",
        "  - 첫 번째 타임 스텝은 이전 출력이 없으므로 일반적으로 0으로 설정\n",
        "  - 각 뉴런은 <strong>가중치도 두 개</strong>를 가진다.(하나는 x_(t), 다른 하나는 y_(t-1)를 위한 것)\n",
        "  <img src=\"https://media.vlpt.us/images/changdaeoh/post/355c3d96-9e65-48fd-9ad6-6b2ba9f116b3/image.png\" width= 50%  height=50%/>\n",
        "  - 즉, Y_(t)는 시간 t=0에서부터 모든 입력에 대한 함수가 된다.\n",
        "- 동일한 뉴런을 타임 스텝마다 하나씩 표현한 위 이미지를, '시간에 따라 네트워크를 펄쳤다'고 말한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HNXeS82gY6C"
      },
      "source": [
        "## 메모리 셀\n",
        "- 타임 스텝 t에서 순환 뉴런의 출력은 이전 타임 스텝의 모든 입력에 대한 함수이므로, 이를 일종의 <strong>메모리</strong> 형태라고 말할 수 있다.\n",
        "- <strong>메모리 셀:</strong> 타임 스텝에 걸쳐서 <strong>어떤 상태를 보존</strong>하는 신경망의 구성 요소\n",
        "- 각 스텝 t에서 셀의 상태 h_(t)는 (h: hidden) 그 타임 스텝의 입력과 이전 타임 스텝의 상태에 대한 함수이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "  <img src=\"https://media.vlpt.us/images/changdaeoh/post/797fafe5-5df8-424e-8adc-fe654afbb43c/image.png\"/>\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REWZx6kRirX2"
      },
      "source": [
        "## 입력과 출력 시퀀스\n",
        "- <strong>벡터-투-시퀀스</strong>\n",
        "  - 각 타임 스텝에서 하나의 입력 벡터를 반복해서 주입하고, 하나의 시퀀스 출력\n",
        "  - ex) 이미지 주입 -> 이미지 캡션 출력\n",
        "\n",
        "- <strong>시퀀스-투-벡터</strong>\n",
        "  - 입력 시퀀스를 주입하고 마지막을 제외한 모든 출력을 무시\n",
        "  - ex) 영화 리뷰에 있는 연속된 단어를 주입 -> 감성 점수 출력(싫다(-1)~좋다(+1))\n",
        "\n",
        "- <strong>시퀀스-투-시퀀스</strong>\n",
        "  - 입력 시퀀스를 받아 출력 시퀀스를 만든다.\n",
        "  - ex) 최근 N일치의 주식가격 주입 -> 각 입력값보다 하루 앞선 가격 출력\n",
        "  - (즉, N-1일 전부터 내일까지)\n",
        "\n",
        "- <strong>인코더-디코더</strong>\n",
        "   - 시퀀스-투-벡터 네트워크(인코더) 뒤에 벡터-투-시퀀스 네트워크(디코더) 연결\n",
        "   - ex) 한 언어의 문장을 다른 언어로 번역\n",
        "   - 인코더: 해당 문장을 하나의 벡터로 변환\n",
        "   - 디코더: 해당 벡터를 다른 언어의 문장으로 디코딩\n",
        "   - 왜 굳이 이중  모델? \n",
        "    - 하나의 시퀀스-투-시퀀스 네트워크보다 성능이 좋다.\n",
        "    - <strong>번역하기 전에 전체 문장이 주입될 때까지 기다려야 하기 때문</strong>\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F99A94F465BD1990B20352F\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCKawGxMmKx3"
      },
      "source": [
        "## RNN 훈련하기\n",
        "- BPTT(Backpropagation Through Time)\n",
        "<img src=\"https://media.vlpt.us/images/changdaeoh/post/333a8501-57cb-4bc6-8e11-4ca2172b4286/image.png\" width=50% height=50%/>\n",
        "\n",
        "  - 타임 스텝으로 네트워크를 펼치고(실제로 펼치진 않음)\n",
        "  - 보통의 역전파를 사용하는 것\n",
        "    - 정방향 패스 동안에는 <strong>모두 동일한 가중치</strong>가 적용된다(즉, 같은 매개변수 W,b사용)\n",
        "    - 그래서 역전파가 진행되면 <strong>모든 타임 스텝에 걸쳐 합산</strong>될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3WzGZHApAMx"
      },
      "source": [
        "## 시계열 예측하기\n",
        "- 시계열: 타임 스텝마다 하나 이상의 값을 가진 시퀀스\n",
        "  - 단변량 시계열: 하나의 값을 가지는 시퀀스(ex) 시간당 접속 사용자 수 예측)\n",
        "  - 다변량 시계열: 여러 값을 가지는 시퀀스(ex) 기업의 분기별 재정 안정성 예측 -> 수입/부채 등 고려)\n",
        "  - 보통 [배치 크기, 타임 스텝 수, 차원 수] 3D배열로 나타냄(단변량은 차원 수가 1)\n",
        "  <img src=\"https://wikidocs.net/images/page/22886/rnn_image6between7.PNG\"/>\n",
        "- 시계열 예측으로 값 대체도 가능\n",
        "  - 누락된 값 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ntg6tagOBF"
      },
      "source": [
        "import numpy as np\n",
        "def generate_time_series(batch_size, n_steps): #====batch_size만큼 n_steps 길이의 여러 시계열 생성\n",
        "  freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)\n",
        "  time= np.linspace(0,1,n_steps) #n_steps개의 0~1사이의 값을 가지는 1d배열 생성\n",
        "  series=0.5*np.sin((time-offset1)*(freq1*10+10))\n",
        "  series +=0.2*np.sin((time-offset2)*(freq1*20+20))\n",
        "  series +=0.1*(np.random.rand(batch_size, n_steps)-0.5) #잡음\n",
        "  return series[..., np.newaxis].astype(np.float32)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbgC9YOiq1LS"
      },
      "source": [
        "n_steps= 50\n",
        "series=generate_time_series(10000, n_steps+1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000,-1]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
        "X_test, y_test=series[9000:, :n_steps], series[9000:,-1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd1U-Z-DrupS",
        "outputId": "1f2d89f9-de27-4b17-fa66-de3a096fde00"
      },
      "source": [
        "series.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 51, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6QoMMwktJrF",
        "outputId": "927ba0ed-ca31-4fd3-cf7e-b744edc34306"
      },
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 50, 1) (7000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTOk77Szr-sh"
      },
      "source": [
        "---------------\n",
        "시계열마다 1개의 값 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1LMzpGctZ2F"
      },
      "source": [
        "### 기준 성능\n",
        "- 가장 간단한 방법: 각 시계열의 마지막 값을 그대로 예측 -> 순진한 예측이라고 함\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmEyA5jote4b",
        "outputId": "f5bf04be-e087-4129-a40f-278089b9454d"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "y_pred=X_valid[:,-1]\n",
        "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.020163413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n76QzBP0t_Jq"
      },
      "source": [
        "- 완전 연결 네트워크를 사용하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Lz1M3xuCGJ"
      },
      "source": [
        "model1 = keras.models.Sequential([\n",
        "                                 keras.layers.Flatten(input_shape=[50,1]),\n",
        "                                 keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJTFxA5Ivtz7",
        "outputId": "418c033c-9a18-4a1b-d3f8-d68ae946c374"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhMWstWnuNRu",
        "outputId": "bbbb4ab1-8035-45f1-ebc4-f333d7ab118e"
      },
      "source": [
        "model1.compile(optimizer='adam', loss='mse')\n",
        "model1.fit(X_train, y_train,validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 2ms/step - loss: 0.2090 - val_loss: 0.0619\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0343\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0208\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0139\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0107\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0090\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0079\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0056\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0ca929a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv4XnncPuhRD"
      },
      "source": [
        "-----------\n",
        "val_loss: 0.0040까지 떨어짐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFbs3bstfkK"
      },
      "source": [
        "### 간단한 RNN 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noMI5184unAq"
      },
      "source": [
        "model2= keras.models.Sequential(\n",
        "                                   keras.layers.SimpleRNN(1, input_shape=[None, 1])) #기본적으로 tanh 활성화 함수를 사용함"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIRKVqbTutlE",
        "outputId": "feff1c4f-c208-4b3e-f685-acb1ced3d5d6"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__pUSbIDuzE6",
        "outputId": "ac06b411-b4f9-4698-ea99-a69f424ab3e0"
      },
      "source": [
        "model2.compile(optimizer='adam', loss='mse')\n",
        "model2.fit(X_train, y_train,validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 3s 8ms/step - loss: 0.2255 - val_loss: 0.1936\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1848 - val_loss: 0.1624\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1564 - val_loss: 0.1382\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1330 - val_loss: 0.1150\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1085 - val_loss: 0.0927\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0879 - val_loss: 0.0733\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0675 - val_loss: 0.0569\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0513 - val_loss: 0.0430\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0390 - val_loss: 0.0320\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0291 - val_loss: 0.0238\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0218 - val_loss: 0.0184\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0171 - val_loss: 0.0152\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0137\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0129\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0125\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0124\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0122\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0121\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0120\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0c785dad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBZwk8V_vk6L"
      },
      "source": [
        "--------\n",
        "val_loss가 0.0119로, 위 간단한 선형 모델인 model1(0.004)보다 좋지 못한 성능이지만, <br>\n",
        "파라미터가 3개로, 51개인 위 모델보다 훨씬 적다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mHDegS-TMhI"
      },
      "source": [
        "### 심층 RNN\n",
        "<img src=\"https://wikidocs.net/images/page/22886/rnn_image8_ver2.PNG\"/>\n",
        "\n",
        "- return_sequences=True로 설정함으로써 시퀀스-투-시퀀스 문제를 풀 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TajPhtDqTs6P"
      },
      "source": [
        "model3= keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20,return_sequences=True, input_shape=[None, 1]),\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True),\n",
        "                                 keras.layers.SimpleRNN(1)\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzwbbItSUNhf",
        "outputId": "ed0a4830-fadf-4d45-94be-1075e92dc063"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 20)          440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, None, 20)          820       \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, 1)                 22        \n",
            "=================================================================\n",
            "Total params: 1,282\n",
            "Trainable params: 1,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8u-4VZtUPvm",
        "outputId": "9f7465fe-634e-4432-a92c-bff0ab7f77e9"
      },
      "source": [
        "model3.compile(optimizer='adam', loss='mse' )\n",
        "model3.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 9s 29ms/step - loss: 0.0330 - val_loss: 0.0039\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0033 - val_loss: 0.0031\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0033 - val_loss: 0.0028\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0029 - val_loss: 0.0026\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 6s 26ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 6s 26ms/step - loss: 0.0020 - val_loss: 0.0020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3497a9cb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgdjmBkLWq6p"
      },
      "source": [
        "-------------------\n",
        "- 최저 0.0019로, model1(0.004)보다 좋은 성능을 보인다.\n",
        "- 하지만, 마지막 층을 굳이 SimpleRNN을 쓸 필요가 없다.\n",
        "  - 마지막 층의 은닉 상태는 크게 필요하지 않다.\n",
        "  - tanh 활성화 함수를 쓴다 -> 즉, -1~1사이의 값이 나온다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V0aiLjOYh_a"
      },
      "source": [
        "#### 마지막 층 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Ksz3VYXAgF"
      },
      "source": [
        "model4= keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20,return_sequences=True, input_shape=[None, 1]),\n",
        "                                 keras.layers.SimpleRNN(20),#=====출력층이 Dense로 바뀌었으니 해당 층이 RNN 마지막 층\n",
        "                                 keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsy2NUNKXMUb",
        "outputId": "8db7725b-99f8-435f-edca-941c31f04293"
      },
      "source": [
        "model4.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (None, None, 20)          440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,281\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIa8eAMWY4xt",
        "outputId": "be057124-3f69-4d96-bf99-5f60b2a9b1f4"
      },
      "source": [
        "model4.compile(optimizer='adam', loss='mse' )\n",
        "model4.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 6s 21ms/step - loss: 0.0401 - val_loss: 0.0041\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0020 - val_loss: 0.0020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3492ed9b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RdU9wxEZoPw"
      },
      "source": [
        "----------------\n",
        "- model3보다 빠르게 수렴(27(model3) -> 19ms)하고 성능(0.0019(model3) -> 0.0018)도 좋다\n",
        "- 또한 출력층의 활성화 함수도 원하는 함수로 바꿀 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdPA4xkOarwO"
      },
      "source": [
        "#### 실험: activation function  바꿔보기\n",
        "- model4에서 activation만 tanh -> relu로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G46YGbmcaRzb"
      },
      "source": [
        "model5= keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20,return_sequences=True, input_shape=[None, 1], activation='relu'),\n",
        "                                 keras.layers.SimpleRNN(20, activation='relu'),\n",
        "                                 keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muMZpnFyalSI",
        "outputId": "7ffba2e0-83e8-4b1c-d5a0-196a69c81d23"
      },
      "source": [
        "model5.compile(optimizer='adam', loss='mse' )\n",
        "model5.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 6s 21ms/step - loss: 0.0865 - val_loss: 0.0066\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 4s 20ms/step - loss: 0.0061 - val_loss: 0.0050\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0049 - val_loss: 0.0044\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0044 - val_loss: 0.0039\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 4s 20ms/step - loss: 0.0037 - val_loss: 0.0041\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 4s 20ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0036 - val_loss: 0.0041\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0036 - val_loss: 0.0034\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0036 - val_loss: 0.0037\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 4s 20ms/step - loss: 0.0036 - val_loss: 0.0033\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 4s 20ms/step - loss: 0.0037 - val_loss: 0.0033\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 4s 20ms/step - loss: 0.0035 - val_loss: 0.0032\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0034 - val_loss: 0.0031\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0033 - val_loss: 0.0031\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.0033 - val_loss: 0.0031\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 4s 19ms/step - loss: 0.0032 - val_loss: 0.0030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f349331e490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}