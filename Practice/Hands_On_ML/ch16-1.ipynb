{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch16-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1H8P_IzMWTl1xFbrXFPeJ8xz3Ut2edEUA",
      "authorship_tag": "ABX9TyNBMjtX19KhjoXfG9S7JqZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PingPingE/Learn_ML_DL/blob/main/Practice/Hands_On_ML/ch16-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG3kbNEBQu4Z"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK8oyhuIJSS1"
      },
      "source": [
        "# RNN과 어텐션을 사용한 자연어 처리\n",
        "- 자연어 문제를 위해 많이 사용하는 방법은 순환 신경망임\n",
        "- 문자 단위 RNN: 문장에서 다음 글자를 예측\n",
        "  - 상태가 없는 RNN: 각 반복에서 무작위하게 택한 텍스트의 일부분으로 학습하고 나머지 텍스트에서 어떤 정보도 사용하지 않음 \n",
        "  - 상태가 있는 RNN: 훈련 반복 사이에 은닉 상태를 유지하고 중지된 곳에서 이어서 상태를 반영 -> 긴 패턴 학습 가능\n",
        "\n",
        "- 단어 단위(시퀀스) RNN\n",
        "- RNN 기반의 인코더-디코더 구조\n",
        "- 어텐션 메커니즘\n",
        "  - 각 타임 스텝에서 모델이 집중해야 할 입력 부분을 선택하도록 학습하는 신경망 구성 요소\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t1tcxWbP6o3"
      },
      "source": [
        "## Char-RNN을 사용해 셰익스피어 문체 생성하기\n",
        "- Char-RNN을 사용해서 한 번에 한 글자씩 새로운 텍스트를 생성할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyl5kR66QUue"
      },
      "source": [
        "### 훈련 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386UaHDJQTtI",
        "outputId": "1a1ae5d0-5a17-4fe9-9c65-019c7aa4b3b1"
      },
      "source": [
        "url=\"https://homl.info/shakespeare\"\n",
        "filepath=keras.utils.get_file(\"shakespeare.txt\", url)\n",
        "with open(filepath) as f:\n",
        "  text=f.read()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sMey42j1ulk",
        "outputId": "e5bb6c52-547b-45bb-fad9-aafb8698e973"
      },
      "source": [
        "len(text)#=== 글자 수가 백만 개 이상"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NDyY_dPm1_ms",
        "outputId": "b3bd8632-3fee-453f-c8eb-154bc688a466"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OqYV93bS3D2"
      },
      "source": [
        "#### 모든 글자를 정수로 인코딩하기 -> 케라스의 Tokenizer클래스 아용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbkgptWCIGUy"
      },
      "source": [
        "tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)#=== 단어 수준이 아닌 글자 수준 인코딩\n",
        "tokenizer.fit_on_texts(text)#=== 텍스트에 훈련"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMXgYSRDUBui"
      },
      "source": [
        "------\n",
        "텍스트에 사용되는 모든 글자를 찾아 글자 ID에 매핑(ID는 1부터 시작)\n",
        "<br><br>\n",
        "- 간단한 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei-nN59cSyFZ",
        "outputId": "47bc3274-ab30-4787-fc55-c759e88032ce"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVUh-iBkTcte",
        "outputId": "f8fc291a-36d8-4773-9841-acce65d99001"
      },
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v9-Y5NZT0Kd"
      },
      "source": [
        "- 전체 텍스트를 인코딩하여 각 글자를 ID로 나타내기\n",
        "  - 1부터 시작하므로 -1해서 0부터 시작하는 걸로 바꿔보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWI2YO-50Mma",
        "outputId": "44fb7697-93e6-4f27-80c8-f48bbf9d7d36"
      },
      "source": [
        "max_id =len(tokenizer.word_index)\n",
        "max_id  #===== 즉, 고유 글자가 39개"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpDcZAPaToNt"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([text]))-1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzX6PlQ7Tx5m",
        "outputId": "addb85f0-8108-498e-eaa5-fc4c8af808cd"
      },
      "source": [
        "encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19,  5,  8, ..., 20, 26, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygtDSNSoUjQR"
      },
      "source": [
        "### 순차 데이터셋을 나누는 방법\n",
        "- 훈련/검증/테스트 세트가 <strong>중복되지 않도록</strong> 만드는 것이 매우 중요\n",
        "  - 예를 들어 텍스트 처음 90%/5%/5%\n",
        "\n",
        "- 시계열을 다룰 때는 보통 <strong>시간</strong>에 따라 나눈다.(안전하다)\n",
        "  - ex)100개의 회사의 재정 건전성 관련 데이터 다루기 \n",
        "    - 많은 회사들이 <strong>강하게 상호 연관</strong>되어 있을 가능성이 높다.\n",
        "    - 훈련 세트와 테스트 세트에 상호 연관된 회사가 있다면 <strong>테스트 세트에서 측정한 일반 오차가 유용하지 않을 것임</strong>\n",
        "    - => 따라서 회사를 기준으로 나누는 등 다른 방법 보다 시간에 따라 나누는 것이 일반적이고, 안전함\n",
        "\n",
        "- 시계열이 <strong>충분히 안정적</strong>인지 꼭 확인해야한다.\n",
        "  - 일반적으로는, 시계열의 패턴이 '변하지 않는다'고 가정하지만, 일부는 그렇지 않음\n",
        "    - ex) 금융 시장은 변덕스럽다. 트레이더가 패턴을 발견한 뒤 적용하려 하면 사라짐\n",
        "  - 안정성 확인 방법: <strong>시간에 따라 검증 세트에 대한 모델의 오차 그려보기</strong>\n",
        "    - 모델이 검증 세트 <strong>마지막보다 첫 부분에서 성능이 더 좋다면</strong> 이 시계열이 충분히 안정되지 않은 것일 수 있음\n",
        "      - 이 경우, <strong>더 짧은 시간 간격</strong>으로 모델을 훈련하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvHO816PXzmk"
      },
      "source": [
        "#### train: 텍스트의 처음 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XFh_FrVUoBe",
        "outputId": "30b86241-85a6-447f-9e4f-725cb27b9df1"
      },
      "source": [
        "dataset_size=tokenizer.document_count#== 전체 글자 개수\n",
        "train_size=dataset_size*90//100 #=== 텍스트의 처음 90%\n",
        "dataset= tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oogztBsCY7XI"
      },
      "source": [
        "### 순차 데이터를 윈도 여러 개로 자르기\n",
        "- 해당 text는 백만 개 이상의 글자로 이루어진 시퀀스 하나\n",
        "- 즉, 이대로 RNN으로 훈련 시키면, 백만 개의 층이 있는 심층 신경망과 같게 된다.\n",
        "- 따라서 <strong>window()메서드</strong>를 사용해서 긴 문자열을 짧은 부분 문자열로 변환한다.\n",
        "- 이 짧은 부분 문자열만큼만 역전파하는게 <strong>TBPTT(Truncated Backpropagation Through Time)</strong>\n",
        "- BPTT vs TBPTT\n",
        "\n",
        "  <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdawXWw%2FbtqD2dngo5l%2FrvitZfPrq5bXlHPUfy07J0%2Fimg.png\" width=50% />\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiRY38%2FbtqD2bweMfV%2FXiaxKlF44miJP4IHATTfQk%2Fimg.png\" width=50%/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kemV5qKyk0j"
      },
      "source": [
        "n_steps=100\n",
        "window_length=n_steps+1\n",
        "dataset=dataset.window(window_length,shift=1,drop_remainder=True) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRVMTGlT5pyc"
      },
      "source": [
        "--------------\n",
        "- window_length: 한 번에 얼마나 볼것인지(너무 짧게 만들면 긴 패턴을 학습할 수 없으므로 적절하게 조절해야함)\n",
        "- shift: 윈도우를 얼마만큼 움직일 것인지(기본값=window 길이 )\n",
        "- drop_remainder:  True로 하면 모든 윈도우가 동일한 개수의 글자를 포함하도록한다.\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-x8nWnf5Y-b"
      },
      "source": [
        "dataset= dataset.flat_map(lambda window: window.batch(window_length)) #=== 윈도우마다 batch(window_length)호출"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNI1-yMA9z0W"
      },
      "source": [
        "--------\n",
        "- flat_map()메서드를 통해서 데이터셋을 변환하고 평평하게 만든다\n",
        "- ex) 기존 데이터셋(ds): {{1,2},{3,4,5,6}} <br>\n",
        "flat_map(lambda ds: ds.batch(2)) ->   {[1,2],[3,4],[5,6]} : 텐서 2개를 가진 데이터셋\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUdUvYkqAyeG"
      },
      "source": [
        "- 섞고, 타깃 값(마지막 1개 글자) 분리\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FY65A7%2FbtqEWB10RrH%2Ff1Ngbw1V4OTxuhbpKRlkr1%2Fimg.png\"/>\n",
        "\n",
        "- 위 예시는 윈도 크기가 11 , 배치 크기가 3인 경우이다.\n",
        "- input이 [2,12] 구간이라면, target은 [3,13]구간의 문자가 되겠다.\n",
        "  - 즉, [2,12]구간의 문자들로 학습을 하면 13번째 문자를 추가로 맞춰야 하는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsFd4L4v-6KV"
      },
      "source": [
        "batch_size=32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset=dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFUhi4LZBcZV"
      },
      "source": [
        "- 입력 특성 원-핫 벡터\n",
        "  - 고유한 글자 수가 적기 때문(39개)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHq_JWIuAXLt"
      },
      "source": [
        "dataset= dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qyh8peiAoWP"
      },
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a79R_tdEB6Ok"
      },
      "source": [
        "### Char-RNN 모델 만들고 훈련하기\n",
        "- 이전 글자 100개를 기반으로 다음 글자를 예측하기 위해 \n",
        "  - 유닛 128개를 가진 GRU층 2개\n",
        "  - 입력과 은닉 상태에 20% 드롭아웃(dropout, recurrent_dropout)\n",
        "  - 출력층은 각 글자에 대한 확률을 출력할 것이므로 softmax, 유닛 max_id개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4hhFHGsB4uf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d456750b-dd46-423b-9313-53b3a91b4d64"
      },
      "source": [
        "model= keras.models.Sequential([\n",
        "                                keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n",
        "                                keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "                                keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_2 (GRU)                  (None, None, 128)         64896     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, None, 128)         99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 39)          5031      \n",
            "=================================================================\n",
            "Total params: 168,999\n",
            "Trainable params: 168,999\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDjbf2MKlIsg",
        "outputId": "08c9f427-90a7-48ca-964a-1e416719669a"
      },
      "source": [
        "cd drive/My Drive/Colab Notebooks/HandsOn/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/HandsOn/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZr0uadekyQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b5326a-1a16-466d-fb2b-049572a7f221"
      },
      "source": [
        "#==학습이 오래 걸리니 중간 중간 저장하자\n",
        "check_point = keras.callbacks.ModelCheckpoint('rnn_{epoch:02d}.h5', monitor='loss', save_freq=3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')\n",
        "history=model.fit(dataset, epochs=20, callbacks=[check_point]) #====너어어어ㅓ무 오래 걸려서 나중에..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31368/31368 [==============================] - 14430s 460ms/step - loss: 1.5899\n",
            "Epoch 2/20\n",
            "23119/31368 [=====================>........] - ETA: 1:02:59 - loss: 1.3688"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCNlj58ib9U"
      },
      "source": [
        "def preprocess(texts):\n",
        "  X=np.array(tokenizer.texts_to_sequences(texts)) -1\n",
        "  return tf.one_hot(X,max_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F2GbM4epCVq"
      },
      "source": [
        "X_new=preprocess([[\"How are yo\"], [\"I'm fin\"]])\n",
        "y_pred=model.predict_classes(X_new)\n",
        "tokenizer.sequences_to_texts(y_pred+1)[0][-1] #첫 번째 문장을 봤을 때 이어질 다음 문자는? -> 학습 20 에포크동안 하면 'u' 잘 나온다고 함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rVuHLCgP8IH"
      },
      "source": [
        "#### 학습이 너무 느린 문제 해결 방법\n",
        "- batch_size를 크게하기\n",
        "- GRU -> CuDNNGRU로 대체하기( tensorflow v1)\n",
        "\n",
        "\n",
        "참고)\n",
        "- [CPU/GPU학습시간 비교](https://bae-gimin.github.io/post/lstm-traintime-test/)\n",
        "- [스택오버플로우]( https://stackoverflow.com/questions/41948406/why-is-my-gpu-slower-than-cpu-when-training-lstm-rnn-models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow20lEb-Sjuf"
      },
      "source": [
        "##### 기존 모델(GRU) + batch_size=256 일 때"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN-nUPrWPjEf"
      },
      "source": [
        "batch_size=256\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset=dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNcm3ekzP7TH"
      },
      "source": [
        "dataset= dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPW9D_H9P7Tp"
      },
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlcUgYTtRtuj",
        "outputId": "e9c03ccd-0e09-4ba9-98f7-58a0aa586fa6"
      },
      "source": [
        "#==학습이 오래 걸리니 중간 중간 저장하자\n",
        "check_point = keras.callbacks.ModelCheckpoint('rnn_{epoch:02d}.h5', monitor='loss', save_freq=3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')\n",
        "history=model.fit(dataset, epochs=20, callbacks=[check_point]) #====너어어어ㅓ무 오래 걸려서 나중에..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3921/3921 [==============================] - 2367s 602ms/step - loss: 2.0082\n",
            "Epoch 2/20\n",
            "3921/3921 [==============================] - 2368s 604ms/step - loss: 1.5375\n",
            "Epoch 3/20\n",
            "3921/3921 [==============================] - 2342s 597ms/step - loss: 1.4879\n",
            "Epoch 4/20\n",
            "3921/3921 [==============================] - 2370s 604ms/step - loss: 1.4653\n",
            "Epoch 5/20\n",
            "3921/3921 [==============================] - 2481s 633ms/step - loss: 1.4526\n",
            "Epoch 6/20\n",
            "2004/3921 [==============>...............] - ETA: 19:19 - loss: 1.4486"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "756uTLvIUpi9"
      },
      "source": [
        "----------\n",
        "- 배치 사이즈가 64였을 때: 14430s 460ms/step - loss: 1.5899\n",
        "  - 14430s -> 2367s \n",
        "  - 460ms/step -> 602ms/step \n",
        "  - loss: 1.5899 -> loss: 2.0082\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmAeuKRQpFLw"
      },
      "source": [
        "### 가짜 셰익스피어 텍스트 생성하기\n",
        "Char-RNN모델로 새로운 텍스트를 생성하려면?\n",
        "- Char-RNN 모델이 예측한 다음 글자를 텍스트 끝에 추가 -> input -> 추가 -> input .... \n",
        "  - 근데 이 방식으로 하면 같은 단어가 계속 반복 됨\n",
        "<br>\n",
        "- tf.random.categorical()함수를 사용해서 모델이 추정한 확률을 기반으로 다음 글자를 무작위로 선택한다면 더 다채로운 텍스트 생성 가능\n",
        "  - 다양성 제어 파라미터: temperature\n",
        "    - 예측 확률에 로그를 취하고(로짓) temperature로 나눔\n",
        "    - 0에 가까울수록 높은 확률을 가진 글자가 선택될 가능성이 더 높아져서 다채로움이 사라짐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAbsy3LTo7__"
      },
      "source": [
        "def next_char(text, temperature=1):\n",
        "  X_new = preprocess([text])\n",
        "  y_proba= model.predict(X_new)[0,-1:,:]\n",
        "  rescaled_logits=tf.math.log(y_proba)/temperature #==== temperature로 나누는 부분\n",
        "  char_id=tf.random.categorical(rescaled_logits, num_samples=1)+1\n",
        "  return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Hv2DxlqmRt"
      },
      "source": [
        "- next_char()함수를 반복 호출해서 다음 글자를 얻고, 텍스트에 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-55_ZjDeqCW1"
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "  for _ in range(n_chars):\n",
        "    text += next_char(text, temperature)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXu3ipavtWpQ"
      },
      "source": [
        "----------\n",
        "- 해당 모델은 1에 가까운 온도에서 가장 잘 작동한다고 함\n",
        "- 해당 모델은 n_steps=100을 넘어가면 훈련이 더 어려워질 것임\n",
        "  - LSTM, GRU셀도 매우 긴 시퀀스는 다루기 어렵다<br>\n",
        "=> 상태가 있는 RNN을 살펴보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2y-srzZty-3"
      },
      "source": [
        "### 상태가 있는 RNN\n",
        "- 지금까지는 상태가 없는 RNN만 사용한 것임\n",
        "  - 훈련 반복마다 모델의 은닉 상태를 0으로 초기화\n",
        "- 상태가 있는 RNN은 한 훈련 배치를 처리한 후 마지막 상태를 다음 훈련 배치의 초기 상태로 사용\n",
        "  - 이렇게 하면 모델의 장기간 패턴 학습 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2wx3I34fpk5"
      },
      "source": [
        "#### 데이터셋 준비\n",
        "- 이전 배치의 시퀀스가 끝난 지점에서 시작해야하므로 순차적이고 겹치지 않는 시퀀스를 만들어야함\n",
        "  - shuffle 하면 안됨\n",
        "  - shift=n_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDGeS4F9hfhr"
      },
      "source": [
        "#### 배치 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZaLLMLh2yx"
      },
      "source": [
        "- 가장 간단한 방법: batch_size=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Lre_ErtUpU"
      },
      "source": [
        "dataset=tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset= dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZGaVzlEcoFc"
      },
      "source": [
        "batch_size=1\n",
        "dataset=dataset.batch(1)\n",
        "dataset=dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset= dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")\n",
        "dataset=dataset.prefetch(1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0DNfCpih5HL"
      },
      "source": [
        "- 어렵지만 좀 더 큰 batch_size로 만드는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpEWs65lhZqL"
      },
      "source": [
        "batch_size = 32\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "    datasets.append(dataset)\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81S-QImfou-"
      },
      "source": [
        "#### 모델 생성\n",
        "- 각 순환 층을 만들 때 stateful=True 지정\n",
        "- 배치에 있는 입력 시퀀스의 상태를 보존해야하므로 배치 크기를 알려줘야함\n",
        "  - batch_input_shape매개변수 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LdYDLGwc-fn",
        "outputId": "c55e8c57-956c-44ab-d6d4-11317c2df338"
      },
      "source": [
        "model2= keras.models.Sequential([\n",
        "                                keras.layers.GRU(128, return_sequences=True, stateful=True,batch_input_shape=[batch_size,None, max_id], dropout=0.2, recurrent_dropout=0.2),\n",
        "                                keras.layers.GRU(128, return_sequences=True, stateful=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "                                keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))\n",
        "])\n",
        "model2.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_2 (GRU)                  (1, None, 128)            64896     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 128)            99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (1, None, 39)             5031      \n",
            "=================================================================\n",
            "Total params: 168,999\n",
            "Trainable params: 168,999\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6e_nhcPgXfi"
      },
      "source": [
        "- 에포크 끝마다 텍스트를 다시 시작하기 전에 상태를 재설정해야함 -> 콜백 함수로 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVVCztx9gOGO"
      },
      "source": [
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self, epoch, logs):\n",
        "    self.model.reset_states()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbfG6ceUgdv3"
      },
      "source": [
        "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "model2.fit(dataset, steps_per_epoch=train_size//batch_size, epochs=50, callbacks=[ResetStatesCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}