{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9Wqz5yqFAgE48KdQHOZhq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PingPingE/Learn_ML_DL/blob/main/Practice/Hands_On_ML/ch16-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG3kbNEBQu4Z"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK8oyhuIJSS1"
      },
      "source": [
        "# RNN과 어텐션을 사용한 자연어 처리\n",
        "- 자연어 문제를 위해 많이 사용하는 방법은 순환 신경망임\n",
        "- 문자 단위 RNN: 문장에서 다음 글자를 예측\n",
        "  - 상태가 없는 RNN: 각 반복에서 무작위하게 택한 텍스트의 일부분으로 학습하고 나머지 텍스트에서 어떤 정보도 사용하지 않음 \n",
        "  - 상태가 있는 RNN: 훈련 반복 사이에 은닉 상태를 유지하고 중지된 곳에서 이어서 상태를 반영 -> 긴 패턴 학습 가능\n",
        "\n",
        "- 단어 단위(시퀀스) RNN\n",
        "- RNN 기반의 인코더-디코더 구조\n",
        "- 어텐션 메커니즘\n",
        "  - 각 타임 스텝에서 모델이 집중해야 할 입력 부분을 선택하도록 학습하는 신경망 구성 요소\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t1tcxWbP6o3"
      },
      "source": [
        "## Char-RNN을 사용해 셰익스피어 문체 생성하기\n",
        "- Char-RNN을 사용해서 한 번에 한 글자씩 새로운 텍스트를 생성할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyl5kR66QUue"
      },
      "source": [
        "### 훈련 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386UaHDJQTtI",
        "outputId": "0162b856-4186-4ca7-be27-a8e8920cea1a"
      },
      "source": [
        "url=\"https://homl.info/shakespeare\"\n",
        "filepath=keras.utils.get_file(\"shakespeare.txt\", url)\n",
        "with open(filepath) as f:\n",
        "  text=f.read()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OqYV93bS3D2"
      },
      "source": [
        "#### 모든 글자를 정수로 인코딩하기 -> 케라스의 Tokenizer클래스 아용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbkgptWCIGUy"
      },
      "source": [
        "tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)#=== 단어 수준이 아닌 글자 수준 인코딩\n",
        "tokenizer.fit_on_texts(text)#=== 텍스트에 훈련"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMXgYSRDUBui"
      },
      "source": [
        "------\n",
        "텍스트에 사용되는 모든 글자를 찾아 글자 ID에 매핑(ID는 1부터 시작)\n",
        "<br><br>\n",
        "- 간단한 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei-nN59cSyFZ",
        "outputId": "b6b68217-3386-40d2-b477-8f1abb54360a"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVUh-iBkTcte",
        "outputId": "2cf91182-4c9b-4ce8-91ea-82d06af2ecbd"
      },
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v9-Y5NZT0Kd"
      },
      "source": [
        "- 전체 텍스트를 인코딩하여 각 글자를 ID로 나타내기\n",
        "  - 1부터 시작하므로 -1해서 0부터 시작하는 걸로 바꿔보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpDcZAPaToNt"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([text]))-1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzX6PlQ7Tx5m",
        "outputId": "1aaf781c-78db-4eb4-c996-b25e4c21d0cd"
      },
      "source": [
        "encoded"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19,  5,  8, ..., 20, 26, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygtDSNSoUjQR"
      },
      "source": [
        "### 순차 데이터셋을 나누는 방법\n",
        "- 훈련/검증/테스트 세트가 <strong>중복되지 않도록</strong> 만드는 것이 매우 중요\n",
        "  - 예를 들어 텍스트 처음 90%/5%/5%\n",
        "\n",
        "- 시계열을 다룰 때는 보통 <strong>시간</strong>에 따라 나눈다.(안전하다)\n",
        "  - ex)100개의 회사의 재정 건전성 관련 데이터 다루기 \n",
        "    - 많은 회사들이 <strong>강하게 상호 연관</strong>되어 있을 가능성이 높다.\n",
        "    - 훈련 세트와 테스트 세트에 상호 연관된 회사가 있다면 <strong>테스트 세트에서 측정한 일반 오차가 유용하지 않을 것임</strong>\n",
        "    - => 따라서 시간에 따라 나누는 것이 일반적이고, 안전함\n",
        "\n",
        "- 시계열이 <strong>충분히 안정적</strong>인지 꼭 확인해야한다.\n",
        "  - 일반적으로는, 시계열이 '변하지 않는다'고 가정하지만, 일부는 그렇지 않음\n",
        "    - ex) 금융 시장은 변덕스럽다. 트레이더가 패턴을 발견한 뒤 적용하려 하면 사라짐\n",
        "  - 안정성 확인 방법: <strong>시간에 따라 검증 세트에 대한 모델의 오차 그려보기</strong>\n",
        "    - 모델이 검증 세트 <strong>마지막보다 첫 부분에서 성능이 더 좋다면</strong> 이 시계열이 충분히 안정되지 않은 것일 수 있음\n",
        "      - 이 경우, <strong>더 짧은 시간 간격</strong>으로 모델을 훈련하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvHO816PXzmk"
      },
      "source": [
        "#### train: 텍스트의 처음 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XFh_FrVUoBe",
        "outputId": "054a4cb0-8ddd-475c-e5f5-b3da896633ad"
      },
      "source": [
        "dataset_size=tokenizer.document_count#== 전체 글자 개수\n",
        "train_size=dataset_size*90//100 #=== 텍스트의 처음 90%\n",
        "dataset= tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oogztBsCY7XI"
      },
      "source": [
        "### 순차 데이터를 윈도 여러 개로 자르기"
      ]
    }
  ]
}