{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch13-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiOstGdMTcjysDtPuYjN4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PingPingE/Learn_ML_DL/blob/main/Practice/Hands_On_ML/ch13-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G7i_FX0xR15"
      },
      "source": [
        "# 텐서플로에서 데이터 적재와 전처리하기\n",
        "\n",
        "- 데이터의 양이 많은 경우, 이를 Binary로 serialization한 후 파일 형태로 저장하고 있다가, 이를 다시 읽어들이는 형태로 처리하면 속도 상의 이득을 기대할 수 있다.\n",
        "- 이를 위해 protocol buffer형태로 serialization을 수행해서 저장할 수 있는 TFRecord 포맷이 필요한 것\n",
        "\n",
        "*참고: [링크](http://solarisailab.com/archives/2603)<br>\n",
        "*protocol buffer: 구글이 개발한 이식성과 확장성이 좋고 효율적인 이진 포맷"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtPUjYt_ydV5"
      },
      "source": [
        "# TFRecord 포맷\n",
        "- <strong>크기가 다른 연속된 이진 레코드</strong>를 저장하는 단순한 이진 포맷\n",
        "- 각 레코드는 길이, 길이가 올바른지 체크하는 CRC 체크섬, 실제 데이터, 데이터를 위한 CRC 체크섬으로 구성\n",
        "- <strong>tf.io.TFRecordWriter 클래스</strong>를 사용해서 TFRecord를 손쉽게 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_g0u6sxkixS"
      },
      "source": [
        "import tensorflow as tf\n",
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f: #TFRecord 만들기\n",
        "  f.write(b\"This is the first record\")\n",
        "  f.write(b\"And this is the second record\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg_UOE2NzDBq"
      },
      "source": [
        "- tf.data.TFRecordDataset을 사용해서 하나 이상의 TFRecord를 읽을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRjdlBWTy9BX",
        "outputId": "153539da-2c89-4ee7-df50-5a1d93118705"
      },
      "source": [
        "filepaths=['my_data.tfrecord']\n",
        "dataset=tf.data.TFRecordDataset(filepaths) \n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dTV-RCQ17cL"
      },
      "source": [
        "------------\n",
        "기본적으로 TFRecordDataset은 파일을 하나씩 차례로 읽는다.\n",
        "<br>-> num_parallel_reads를 지정해서 여러 파일에서 레코드를 번갈아 읽을 수 있다(DataAPI의 list_files()+interleave()와 동일한 결과)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMFQvSrj2NdC"
      },
      "source": [
        "## 압축된 TFRecord 파일\n",
        "- 네트워크를 통해 읽어야 하는 경우, TFRecord파일을 압축할 필요가 있다.\n",
        "- options 매개변수를 이용해서 압축된 TFRecord 파일을 만들 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpjqA5tP2QU6"
      },
      "source": [
        "options=tf.io.TFRecordOptions(compression_type=\"GZIP\") #압축 형식 지정\n",
        "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
        "  f.write(b\"(compressed)This is the first record\")\n",
        "  f.write(b\"(compressed)And this is the second record\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcMY_122uGO",
        "outputId": "166b18e1-44bc-47f4-e6e2-6bef39288c16"
      },
      "source": [
        "filepaths=['my_compressed.tfrecord']\n",
        "dataset=tf.data.TFRecordDataset(filepaths, compression_type=\"GZIP\") #압축된걸 읽을 때도 compression_type을 지정해야 한다\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'(compressed)This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'(compressed)And this is the second record', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ5nFIbZ3NB4"
      },
      "source": [
        "## 프로토콜 버퍼 개요\n",
        "- 각 레코드는 어떤 이진 포맷도 사용할 수 있지만, 일반적으로 TFRecord는 직렬화된 프로토콜 버퍼를 담는다.\n",
        "\n",
        "\n",
        "- 프로토콜 버퍼의 정의\n",
        "```\n",
        "syntax=\"proto3\"#포맷 버전 3\n",
        "#Person 객체 생성\n",
        "message Person{\n",
        "    string name=1;\n",
        "    int32 id=2;\n",
        "    repeated string email=3; #string 타입의 email필드를 하나 이상 가진다.\n",
        "}\n",
        "```\n",
        "\n",
        "------\n",
        "- 프로토콜 버퍼 객체는 직렬화해서 전송된 것을 의미하므로 message라고 부른다.\n",
        "- 각 필드에 부여된 1,2,3 값은 필드 식별자로, 레코드의 이진 표현에 사용된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whqMG2Ar9F5C"
      },
      "source": [
        "### 텐서플로 프로토콜 버퍼\n",
        "- TFRecord 파일에서 사용하는 전형적인 주요 프로토콜 버퍼는 <strong>데이터셋에 있는 하나의 샘플을 표현하는 Example 프로토콜 버퍼다.</strong>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2yW8VAu-OCp"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "syntax=\"proto3\"\n",
        "message BytesList {repeated bytes value=1;}\n",
        "message FloatList {repeated float value=1 [packed=True];}\n",
        "message Int64List {repeated int64 value=1 [packed=True];}\n",
        "message Feature{\n",
        "    oneof kind{\n",
        "        BytesList bytes_list=1;\n",
        "        FloatList float_list=2;\n",
        "        Int64List int64_list=3;\n",
        "    }\n",
        "};\n",
        "message Features {map<string, Feature> feature=1; };\n",
        "message Example {Features features=1; };\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEnsU8eF9lzg"
      },
      "source": [
        "--------\n",
        "- [packed=True]는 효율적인 인코딩을 위해 반복적인 수치 필드에 사용된다.\n",
        "- Feature는 BytesList, FloatList, Int64List 중 하나를 담는다.\n",
        "- Features는 특성이름과 특성값을 매핑한 딕셔너리\n",
        "- Example은 하나의 Features 객체를 가진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jf6JG9-3r0i"
      },
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Feature, Features, Example\n",
        "\n",
        "person_example=Example(\n",
        "    features=Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
        "            \"id\":Feature(int64_list=Int64List(value=[123])),\n",
        "            \"emails\":Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
        "        }\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT1gx_-V1p4r"
      },
      "source": [
        "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
        "  f.write(person_example.SerializeToString()) #직렬화하고 결과 데이터를 tfrecord파일에 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD_l64Hq_Sq-"
      },
      "source": [
        "-----------------------\n",
        "보통은 현재 포맷(csv파일 같은)을 읽어 각 샘플마다 하나의 Example 프로토콜 버퍼를 생성하고, 위와 같이 저장한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JozSEHuHACQx"
      },
      "source": [
        "### Example 프로토콜 버퍼를 읽고 파싱하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zCgIpIjAJl4"
      },
      "source": [
        "#설명 딕셔너리\n",
        "feature_description={\n",
        "    \"name\":tf.io.FixedLenFeature([], tf.string,default_value=\"\"),\n",
        "    \"id\":tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    \"emails\":tf.io.VarLenFeature(tf.string),  #repeated이므로 특성 리스트 길이가 가변적\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx7dXHSj_FzX"
      },
      "source": [
        "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
        "  parsed_example=tf.io.parse_single_example(serialized_example, feature_description) #parse_example()로 배치 단위로 파싱할 수도 있다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "yq478IgSBWmu",
        "outputId": "23b19dc6-7f7d-4a6c-e0c8-91376698f3ad"
      },
      "source": [
        "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
        "  parsed_example=tf.io.parse_single_example(serialized_example) #설명 딕셔너리 없으면 error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f0aae96c6b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mserialized_example\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"my_contacts.tfrecord\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mparsed_example\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: parse_single_example_v2() missing 1 required positional argument: 'features'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ial5bASJBkVu"
      },
      "source": [
        "- 가변 길이 특성은 희소 텐서로 파싱된다(고정 길이 특성은 보통의 텐서)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a2uuwfwA7mr",
        "outputId": "9e5b4f04-15ca-4cc4-bced-ff53ed53e82b"
      },
      "source": [
        "tf.sparse.to_dense(parsed_example['emails'], default_value=b\"\") #희소 -> 밀집 변환"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp8GmSD8BBwe",
        "outputId": "67df97ba-e082-4fae-cbcf-609a0ff440fd"
      },
      "source": [
        "parsed_example['emails'].values #근데 굳이 변환 할 필요 X 바로 참조하는 것이 더 간단"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R0N1cWDCnrB"
      },
      "source": [
        "### SequenceExample 프로토콜 버퍼를 사용해서 리스트의 리스트 다루기\n",
        "\n",
        "- SequenceExample 프로토콜 버퍼의 정의\n",
        "\n",
        "```\n",
        "message FeatureList { repeated Feature feature=1;};\n",
        "message FeatureLists {map<string, FeatureList> feature_list =1;};\n",
        "message SequenceExample{\n",
        "  Features context=1;\n",
        "  FeatureLists feature_lists=2;\n",
        "};\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kgHeoR0FF6N"
      },
      "source": [
        "------------\n",
        "- 문맥 데이터를 위한 하나의 Features 객체와 이름이 있는 한 개 이상의 FeatureList를 가진 FeatureLists 객체를 포함한다.\n",
        "- Feature 객체는 바이트 스트링, 64비트 정수, 실수의 리스트 중 하나\n",
        "- 나머지 과정은 Example을 만들고 직렬화하고 파싱하는 것과 비슷"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPN8vL6GGEUt"
      },
      "source": [
        "# 입력 특성 전처리\n",
        "- 신경망을 위해 데이터를 준비하려면 일반적으로 모든 특성을 <strong>수치  특성</strong>으로 변환하고 <strong>정규화</strong>해야 한다.\n",
        "- 방법: pandas, numpy, scikit learn, Data API, 전처리 층(Lambda 층 등)포함 등"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwuiKTnLA8p4"
      },
      "source": [
        "## 전처리 담당 Lambda 층 포함하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh9zI1-0EQi8"
      },
      "source": [
        "- 방법 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub-e0VUV_z4m"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "X_train=tf.constant([1.,2.,3.])\n",
        "means=np.mean(X_train, axis=0, keepdims=True)\n",
        "stds=np.std(X_train, axis=0, keepdims=True)\n",
        "eps=keras.backend.epsilon()\n",
        "\n",
        "model=keras.models.Sequential([\n",
        "                              keras.layers.Lambda(lambda inputs: (inputs-means)/(stds+eps)),\n",
        "                              keras.layers.Dense(5),\n",
        "                              keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL8EUbABEU6U"
      },
      "source": [
        "- 방법 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO_6ucKzAB6h"
      },
      "source": [
        "class Standardization(keras.layers.Layer):\n",
        "  def adapt(self, data_sample):\n",
        "    self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "    self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "  def call(self, inputs):\n",
        "    return (inputs-self.means_)/(self.stds_+keras.backend.epsilon())\n",
        "\n",
        "std_layer=Standardization()\n",
        "std_layer.adapt(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9KAeOqZEXdR"
      },
      "source": [
        "------------\n",
        "방법 1은 mean, std를 전역으로 선언해서 Lambda 층에 활용했고, <br>\n",
        "방법 2는 사용자 정의 층을 만들어서 mean, std를 따로 계산하는 adapt 메서드를 만들었다. \n",
        "\n",
        "=> keras에는 \"LayerNomalization\"과 \"BatchNormalization\" 층이 구현되어 있다. \n",
        "[링크](https://keras.io/api/layers/normalization_layers/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9IOzFHYDpmX"
      },
      "source": [
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcdaNCJ%2FbtqAa7RVwhD%2FP60H1iai2Mxgvu09TGQpv0%2Fimg.png\" width=80% height=80%/>\n",
        "\n",
        "\n",
        "출처: [링크](https://wingnim.tistory.com/92)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rs7KaZdI1bU"
      },
      "source": [
        "## 원-핫 벡터를 사용해서 범주형 특성 인코딩하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ5D4MLLN1Li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b148da-a223-4072-9cd5-542c300b97ff"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "california=fetch_california_housing()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5vlrH1eOAPw",
        "outputId": "9382c9fa-2ab3-4d51-aa08-48b41476603f"
      },
      "source": [
        "california.feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MedInc',\n",
              " 'HouseAge',\n",
              " 'AveRooms',\n",
              " 'AveBedrms',\n",
              " 'Population',\n",
              " 'AveOccup',\n",
              " 'Latitude',\n",
              " 'Longitude']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gy_2h0AEgDy"
      },
      "source": [
        "### 1. 룩업테이블로 각 범주를 인덱스(0~4)로 매핑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBoh8Os4I90Z"
      },
      "source": [
        "vocab=['<1H OCEAN', 'INLAND','NEAR OCEAN', 'NEAR BAY', 'ISLAND'] #범주 리스트(어휘 사전) 생성\n",
        "indices= tf.range(len(vocab), dtype=tf.int64) #위 범주에 해당하는 index 생성\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices) #범주 리스트와 인덱스를 전달하여 룩업 테이블 초기화 객체 생성(TextFileInitalizer도 있음 찾아보기)\n",
        "num_oov_buckets=2 #oov: out of vocabulary => 룩업 테이블에 없는 범주를 찾으면 할당할 공간\n",
        "table=tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets) #룩업테이블 만들기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjfW4nq0GJHv"
      },
      "source": [
        "--------------------\n",
        "oov(out-of-vocabulary) 버킷을 사용하는 이유?\n",
        "\n",
        "-> 범주 개수가 많고 데이터셋이 크거나 범주가 자주 바뀐다면 전체 범주 리스트를 구하는 것이 어려울 수 있다.\n",
        "\n",
        "-> 그래서 oov 버킷을 충분히 확보해서 <strong>훈련 도중 발견되는 알려지지 않은 범주를 버킷에 할당</strong>하게 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KkhnCa0Gh0D",
        "outputId": "7afded89-2c5c-4f32-d0c1-dcd99649b862"
      },
      "source": [
        "categories= tf.constant(['NEAR BAY', 'DESERT', 'INLAND', 'INLAND'])\n",
        "cat_indices=table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXYXby45HCjS"
      },
      "source": [
        "------------\n",
        "기존 룩업 테이블에 없던 DESERT는 새로운 인덱스(oov 버킷)인 5에 매핑되었다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gK0bccXI6l4"
      },
      "source": [
        "### 2. 인덱스 -> 원-핫 벡터로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5F3HxFOG-2-",
        "outputId": "96b799a0-c5c1-45c9-b672-e5ef8929f4ef"
      },
      "source": [
        "cat_one_hot=tf.one_hot(cat_indices, depth=len(vocab)+num_oov_buckets)\n",
        "cat_one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ja5ZbiHemU"
      },
      "source": [
        "-----------------\n",
        "어휘 사전 크기 + oov 버킷 수를 인자로 넘긴 tf.one_hot()함수를 사용해서 변환한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0tt9uDmKCUI"
      },
      "source": [
        "### TextVectorization\n",
        "-  keras에는 <strong>TextVectorization</strong> 층이 구현되어 있다. \n",
        "- 해당 층에서 어휘 사전을 추출하고, 각 범주를 어휘 사전에 있는 인덱스로 변환한다.\n",
        "- 이후 원-핫 벡터로 바꾸고 싶다면 이 층을 모델의 시작부분에 추가하고 뒤이어 tf.one_hot()함수가 적용된 Lambda 층을 놓으면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTq7e4o8JjO-"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.experimental.preprocessing.TextVectorization(input_shape=(1,)),\n",
        "                                 keras.layers.Lambda(lambda x: tf.one_hot(x,depth=10)),#===== one-hot vector로 변환\n",
        "                                 keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZm_MbUpKlk1",
        "outputId": "9d097466-2bd1-499c-d38b-e2fb8c79a486"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization_3 (TextVe (None, None)              0         \n",
            "_________________________________________________________________\n",
            "lambda_3 (Lambda)            (None, None, 10)          0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, None, 10)          110       \n",
            "=================================================================\n",
            "Total params: 110\n",
            "Trainable params: 110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be02hRasJD-K"
      },
      "source": [
        "## 임베딩을 사용해서 범주형 특성 인코딩하기 \n",
        "- 임베딩은 범주를 표현하는 <strong>훈련 가능한 밀집 벡터</strong>이다.\n",
        "  - ex) \"NEAR BAY\" => [0.131,0.890] 같은 벡터로 표현할 수 있다. \n",
        "- <strong>차원 수</strong>는 수정 가능한 하이퍼파라미터이다.\n",
        "- <strong>비슷한 범주는 경사하강법이 더 가깝게</strong> 만들 것이다.\n",
        "  - ex) 'NEAR BAY'와 'NEAR OCEAN'은 점점 가까워 질 것이고, 'INLAND'와는 점점 멀어질 것이다.\n",
        "- 범주가 유용하게 표현되도록 임베딩이 훈련되는 경향이 있고, 이걸 <strong>표현 학습</strong>이라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJRb7qXN1ns"
      },
      "source": [
        "### 임베딩 행렬을 만들어 랜덤하게 초기화하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EKg9qbUN712"
      },
      "source": [
        "embedding_dim =2 #튜닝해야함\n",
        "embed_init = tf.random.uniform([len(vocab)+num_oov_buckets, embedding_dim]) #여기도 범주 개수와 oov 버킷 수를 넉넉하게 준다\n",
        "embedding_matrix=tf.Variable(embed_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfaZDo_1OIh5",
        "outputId": "44c2941f-e3a5-47d2-eafb-08d05232ff32"
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.7971518 , 0.39144683],\n",
              "       [0.03259015, 0.94990695],\n",
              "       [0.7508023 , 0.2669989 ],\n",
              "       [0.0223366 , 0.3709513 ],\n",
              "       [0.71096456, 0.73969376],\n",
              "       [0.51081514, 0.8366407 ],\n",
              "       [0.24649072, 0.64702   ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqwMDJ-UAxG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f669bf4c-706b-4ac8-bbe1-85a43e06c48c"
      },
      "source": [
        "categories= tf.constant(['NEAR BAY', 'DESERT', 'INLAND', 'INLAND'])\n",
        "cat_indices=table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdp02tV1Oxsb",
        "outputId": "10b7c624-d48e-434f-a8a1-92edeb0d4376"
      },
      "source": [
        "tmp_res=tf.nn.embedding_lookup(embedding_matrix, cat_indices)\n",
        "tmp_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.0223366 , 0.3709513 ],\n",
              "       [0.51081514, 0.8366407 ],\n",
              "       [0.03259015, 0.94990695],\n",
              "       [0.03259015, 0.94990695]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Ctj9qikyPP2_",
        "outputId": "319e5fb1-43f9-4a8a-d38c-7aeea17ef1ce"
      },
      "source": [
        "import seaborn as sns\n",
        "#찍어보자(훈련 전임)\n",
        "sns.scatterplot(x=tmp_res[:,0], y=tmp_res[:,1],hue=categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faabcb1e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoluTHyAQh7t"
      },
      "source": [
        "### Keras의 Embedding층"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u0D3kA9QSPg"
      },
      "source": [
        "- 기본적으로 학습가능한 임베딩 행렬을 처리해주는 keras의 Embedding 층이 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLpg2wGbQ3I9",
        "outputId": "c3990135-a7e7-47e3-9e18-50492f496523"
      },
      "source": [
        "embedding=keras.layers.Embedding(input_dim=len(vocab)+num_oov_buckets, output_dim=embedding_dim)\n",
        "tmp_res2=embedding(cat_indices)\n",
        "tmp_res2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[-0.03490963, -0.00526176],\n",
              "       [ 0.03720801,  0.0471353 ],\n",
              "       [ 0.04819093,  0.0488869 ],\n",
              "       [ 0.04819093,  0.0488869 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "KUZ4DxBTRNOS",
        "outputId": "fa13e55a-db25-43a8-b74f-532c8be1196e"
      },
      "source": [
        "#찍어보자(훈련 전임)\n",
        "sns.scatterplot(x=tmp_res2[:,0], y=tmp_res2[:,1],hue=categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faaba0293d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyXsY_ovRiue"
      },
      "source": [
        "- 모두 연결해서 범주형 특성을 처리하고 각 범주마다 임베딩을 학습하는 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIwIjZ54RhM-"
      },
      "source": [
        "regular_inputs=keras.layers.Input(shape=[8]) #샘플마다 8개의 특성을 담은 입력\n",
        "categories=keras.layers.Input(shape=[], dtype=tf.string)\n",
        "\n",
        "cat_indices=keras.layers.Lambda(lambda x: table.lookup(x))(categories) #범주의 인덱스를 찾는다\n",
        "cat_embed=keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
        "\n",
        "encoded_inputs=keras.layers.concatenate([regular_inputs, cat_embed]) #=== 신경망에 주입될 인코드된 입력\n",
        "outputs=keras.layers.Dense(1)(encoded_inputs)\n",
        "model=keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUTZZI66bAAJ"
      },
      "source": [
        "-------------\n",
        "- 원래 원-핫 인코딩 다음에 뒤따르는 Dense 층이 Embedding 층과 동일한 역할을 한다.\n",
        "  - ex) 길이가 20인 원-핫 벡터와 10개의 유닛을 가진 Dense층 = input_dim=20, output_dim=10인 Embedding 층\n",
        "- 그런데 Embedding 층이 더 적은 연산을 사용한다.(임베딩 행렬 크기가 커질 수록 더욱 차이가 커짐)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzsl37lPJwfd"
      },
      "source": [
        "# TF 변환\n",
        "- 전처리는 계산 비용이 크기 때문에 훈련과 동시에 수행하는 것보다 <strong>사전에 처리하면 속도를 크게 높일 수 있다.</strong>\n",
        "- 즉, 데이터가 훈련하는 동안 epoch마다 전처리 되는 것이 아닌, <strong>훈련하기 전에 샘플마다 한 번씩만</strong> 전처리된다.\n",
        "- 만약 RAM에 모든 데이터가 올라갈 수 있다면 cache()메서드, 아니면 Apache Beam이나 Spark 같은 도구가 도움이 된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkkpZSu6KUXG"
      },
      "source": [
        "## 문제점: 훈련/서빙 왜곡\n",
        "- 모델을 앱에 배포할 때, 모델에 주입될 데이터를 <strong>전처리하기 위해 앱마다 코드를 추가</strong>할 것이다.\n",
        "- 그럼 전처리 과정을 바꿀 때마다 아파치 빔, 모바일 앱, 자바 스크립트 등의 코드를 수정해야하는가? -> 그럼 <strong>시간도 많이 걸리고, 에러를 만들기 쉬울 것이다.</strong>\n",
        "- 이렇듯 훈련 전에 수행한 전처리 연산과 앱이나 브라우저에서 수행하는 전처리가 차이가 날 수있는데, 이걸 <strong>훈련/서빙 왜곡</strong>이라 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNqIDmkBLjcR"
      },
      "source": [
        "### 해결 방법\n",
        "- 훈련된 모델을 받아 배포하기 전에 <strong>전처리를 담당하는 층을 동적으로 추가</strong>하는 방법(즉 아파치 빔(or 스파크) 코드와 전처리 층의 코드로 구분)\n",
        "- <strong>전처리 연산을 딱 한 번만</strong> 정의하려면? <strong>TF 변환</strong>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa04ZN81MMaN"
      },
      "source": [
        "#pip install tensorflow_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5auF_9GKS9E"
      },
      "source": [
        "import tensorflow_transform as tft\n",
        "def preprocess(inputs): #이렇게 함수로 전처리 연산을 한 번만 정의\n",
        "  median_age=inputs['housing_median_age']\n",
        "  ocean_proximity=inputs['ocean_proximity']\n",
        "  standardized_age=tft.scale_to_z_score(median_age)\n",
        "  ocean_proximity_id=tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "  return{\n",
        "      \"standardized_median_age\":standardized_age,\n",
        "      \"ocean_proximity_id\":ocean_proximity_id\n",
        "  }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb9QYlX7Jii0"
      },
      "source": [
        "-------------\n",
        "- TF 변환은 <strong>배포할 모델에 추가</strong>할 수 있도록 동일한 역할을 수행하는 <strong>텐서플로 함수</strong>를 생성한다는 것이 중요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvJoInvAJcXK"
      },
      "source": [
        "# 텐서플로 데이터셋(TFDS) 프로젝트\n",
        "- TFDS: 텐서플로우 데이터셋으로, 널리 사용되는 표준 데이터셋을 제공해준다.\n",
        "- 이미지, 텍스트, 오디오,비디오 데이터셋이 포함 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoUnAVL8NMWd"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "dataset=tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_Test = dataset[\"train\"], dataset[\"test\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wewRDkTIPJKt"
      },
      "source": [
        "- 디폴트는 딕셔너리 형태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WXsTj4GL2ri"
      },
      "source": [
        "mnist_train=mnist_train.shuffle(10000).batch(32).prefetch(1)\n",
        "for item in mnist_train: #딕셔너리 형태로 나온다\n",
        "  images=item['image']\n",
        "  labels=item['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXggSEuAPG1b"
      },
      "source": [
        "- 딕셔너리 -> 튜플"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X29zAVBiNxex"
      },
      "source": [
        "#keras는 튜플을 기대하므로 바꾼다.\n",
        "mnist_train=mnist_train.shuffle(10000).batch(32)\n",
        "mnist_train=mnist_train.map(lambda items:(items['image'], items['label'])) #map 메서드 적용\n",
        "mnist_train=mnist_train.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmCx81MbO69x"
      },
      "source": [
        "- 더 간단하게 keras에 전달하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzVo2g4GOZ-D"
      },
      "source": [
        "dataset=tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
        "mnist_train=dataset[\"train\"].prefetch(1)\n",
        "model=keras.models.Sequential([]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_dyQX95PQPC"
      },
      "source": [
        "# 연습문제\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejzLPgeFPjeE"
      },
      "source": [
        "1. 왜 데이터API를 사용하나요?\n",
        "\n",
        "  - 데이터 API는 <strong>대용량 데이터셋을 읽고 효율적으로 전처리</strong>하기 위한 많은 기능을 제공한다. \n",
        "  - 다양한 소스에서 데이터를 적재하거나 / 동시에 여러 소스에서 데이터를 읽고 / 변환하고 / 레코드를 교대로 처리하고 / 섞고 / 배치와 프리패치 기능도 제공한다.\n",
        "\n",
        "\n",
        "\n",
        "2. 대용량 데이터셋을 여러 파일로 나누면 어떤 장점이 있는지?\n",
        "\n",
        "  - 셔플링 버퍼를 사용해서 데이터를 잘게 섞기 전에 <strong>크게 섞을 수 있다.</strong>\n",
        "  - <strong>하나의 큰 파일보다 수천 개의 작은 파일을 다루는 것이 쉽다.</strong>\n",
        "\n",
        "\n",
        "\n",
        "3. 훈련 과정에서 입력 파이프라인의 병목을 어떻게 찾는지? 병목현상을 고칠 순 있나요?\n",
        "\n",
        "  - <strong>텐서보드</strong>를 사용해서 시각화 할 수 있다. \n",
        "  - GPU가 완전히 활용되지 않고 입력 파이프라인에 병목현상이 보인다면 <strong>여러 스레드에서 동시에 데이터를 읽고 전처리하여 몇 개의 배치를 프리패치</strong>해서 해결할 수 있다.\n",
        "  - 만약 위 방법으로도 병목현상이 보인다면, 전처리 코드를 최적화 한다. (데이터 셋을 쪼개고 미리 전처리)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj4W4O7AFODr"
      },
      "source": [
        "4. 어떤 이진 데이터도 TFRecord 파일 또는 직렬화된 프로토콜 버퍼로 저장할 수 있나요?\n",
        "    \n",
        "    - TFRecord파일은 <strong>임의의 이진 레코드의 시퀀스</strong>로 구성된다.\n",
        "    - TFRecord 파일의 <strong>각 레코드에는 원하는 어떤 이진 데이터도 저장</strong>할 수 있다\n",
        "    - 대부분 TFRecord파일은 <strong>직렬화된 프로토콜 버퍼의 시퀀스</strong>를 가지는데, 그 이유는 <strong>여러 프로토콜 버퍼의 장점</strong>을 사용할 수 있기 때문이다.\n",
        "    - <strong>다양한 플랫폼과 언어</strong>에서 쉽게 읽을 수 있고 <strong>호환성</strong>을 유지하면서 프로토콜 정의를 업데이트할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "5. 모든 데이터를 Example 프로토콜 버퍼 포맷으로 변환해야하나요? 자신만의 프로토콜 버퍼 정의를 사용하는 것은 어떤가요?\n",
        "\n",
        "  - Example 프로토콜 포맷은 텐서플로가 몇 가지 파싱 연산(tf.io.parse*example()함수)을 제공하므로 굳이 자신만의 포맷을 정의할 필요가 없다.(가능하긴 함)\n",
        "  - 또한, 이 포맷은 아주 유연하므로 대부분의 데이터셋에 있는 샘플을 표현할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "6. TFRecord를 사용할 때 언제 압축을 사용하는지? 왜 기본적으로 압축을 사용하지 않나요?\n",
        "  - 압축을 하는 이유: 훈련 스크립트로 TFRecord파일을 다운로드해야할 때, 파일 크기와 속도를 줄이기 위해\n",
        "  - 근데 파일이 <strong>훈련 스크립트와 같은 머신</strong>에 있다면, 압축을 해제하기 위한 <strong>CPU 자원을 소모하지 않기 위해</strong> 압축 하지 않는다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzCv9DhJFOSp"
      },
      "source": [
        "7. 데이터 파일을 작성할 때, 또는 tf.data 파이프라인 안에서, 모델의 전처리 층에서, TF 변환을 사용해서 데이터를 전처리 할 수 있습니다. 각 방식의 장단점은?\n",
        "\n",
        "  ■데이터 파일을 작성할 때\n",
        "    \n",
        "    [장점]\n",
        "    - 실시간으로 전처리를 수행할 필요가 없어서 <strong>스크립트가 빨리 실행</strong>될 것이다.\n",
        "    - 어떤 경우는 <strong>전처리된 데이터가 원본 데이터보다 크기가 작아서</strong> 다운 속도가 빠르고 공간을 절약할 수 있다.\n",
        "\n",
        "   [단점]\n",
        "      - <strong>전처리 로직마다 전처리된 데이터셋을 생성</strong>해야 함 -> 여러 로직을 실험하기 어렵다 \n",
        "      - 데이터 증식을 수행하려면 <strong>데이터셋의 변종</strong>을 미리 만들어놔야 해서 <strong>디스크 공간</strong>이 많이 필요하고 <strong>생성 시간</strong>도 오래 걸린다.\n",
        "\n",
        "      <br><br>\n",
        "  \n",
        "  ■tf.data 파이프라인\n",
        "\n",
        "    [장점]\n",
        "    - 전처리 로직을 <strong>변경</strong>하고 데이터 증식을 <strong>적용</strong>하기 쉽다.\n",
        "    - 멀티스레딩, 프리페칭 등 더 <strong>효율적인</strong> 전처리 파이프라인을 만들 수 있다.\n",
        "\n",
        "  [단점]\n",
        "      - <strong>훈련 속도</strong>가 느려진다.\n",
        "      - 데이터 파일을 만들 때 딱 한 번만 데이터를 전처리하는 것이 아닌, <strong>에포크마다 전처리</strong> 한다. \n",
        "\n",
        "      <br><br>\n",
        "\n",
        "  ■모델의 전처리 층\n",
        "\n",
        "     [장점]\n",
        "    - 훈련과 추론을 위해 <strong>딱 한 번만 전처리 코드를 작성</strong>하면 된다.(여러 플랫폼에 배포해야 할 때 큰 장점)\n",
        "    - 모델의 일부분이라서 <strong>잘못된 로직을 사용할 위험이 없다.</strong>\n",
        "\n",
        "  [단점]\n",
        "      - 훈련 속도가 느려진다.\n",
        "      - 에포크마다 전처리\n",
        "      - 각 배치의 전처리 연산이 GPU에서 실행된다. -> 즉, CPU의 멀티스레딩 및 프리페칭을 사용할 수 없다 (근데 케라스 전처리 층은 전처리 연산을 층에서 떼어내 tf.data 파이프라인의 일부로 실행할 수 있어서 멀티스레딩 및 프리페칭의 이점을 얻을 수 있을 것이라고 한다.)\n",
        "\n",
        "      <br><br>\n",
        "      \n",
        "  ■TF변환\n",
        "    \n",
        "    [장점]\n",
        "    - 데이터를 실제로 만들기 때문에 각 샘플이 딱 한 번만 전처리된다.(훈련 속도가 높아진다\n",
        "    - 전처리 층이 자동으로 생성되어서 코드를 한 번만 작성하면 된다.\n",
        "\n",
        "  [단점]\n",
        "      - 사용법을 익혀야한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X3r-GEcFOmF"
      },
      "source": [
        "8. 범주형 특성을 인코딩할 수 있는 대표적인 방법을 나열해보세요. 텍스트 데이터는 어떻게 인코딩할 수 있나요?\n",
        "\n",
        "  - '나쁨'/'보통'/'좋음'과 같이 <strong>순서가 있는 범주형</strong> 특성은 순서가 있는 인코딩을 사용한다. -> '나쁨':0, '보통':1, '좋음':2\n",
        "  - 하지만 대부분의 범주형 특성은 내제된 순서가 없다. ex) 나라, 직업 등 -> <strong>원-핫 인코딩 or 임베딩(범주가 많은 경우)</strong>\n",
        "  - 텍스트는 <strong>BoW표현</strong>을 사용하는 방법이 있다. \n",
        "    - BoW: Bag of Words\n",
        "      - 전체 문서 집합의 단어들의 <strong>단어집</strong>을 만든 후, 특정 문서에서 단어집에 포함된 <strong>단어가 얼마나 자주 사용되었는지 횟수</strong>를 포함하는 각 문서에 대한 <storng>피처 벡터</strong>를 만든다. [참고](https://nlp.gitbook.io/book/nlp_basic/count-vector)\n",
        "    - <strong>사전 훈련된 단어 임베딩</strong>을 사용해서 각 단어를 인코딩할 수 있다.\n",
        "    - 단어를 인코딩하는 대신 <strong>각 글자를 인코딩하거나 부분 토큰을 인코딩</strong>할 수도 있다."
      ]
    }
  ]
}